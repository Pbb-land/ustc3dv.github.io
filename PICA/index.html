<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="PICA: Physics-Integrated Clothed Avatar">
  <meta name="keywords" content="3D-GS, clothed avatar reconstruction, animation">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>PICA</title>

  <!-- Bootstrap -->
  <link href="static/css/bootstrap-4.4.1.css" rel="stylesheet">
  
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <script type="module" src="https://unpkg.com/@google/model-viewer/dist/model-viewer.min.js"></script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h2 class="title is-2 publication-title" style="margin-top: 0; margin-bottom: 2">PICA: Physics-Integrated Clothed Avatar</h2>
            <!-- <h2 class="title is-4 publication-title" style="margin-top: 0; margin-bottom: 0">SIGGRAPH Asia 2022 (Journal Track)</h2> -->
          <h2 class="title is-4 publication-title" style="color:#6e6e6e;margin-top: 2; margin-bottom: 2">ArXiv</h2>
          <!-- <h2 class="title is-2 publication-title" style="margin-top: 0"></h2> -->

          <div class="is-size-5 publication-authors">
            <span class="author-block">Bo Peng</a></span>&nbsp;&nbsp;&nbsp;&nbsp;
            <span class="author-block">Yunfan Tao</a></span>&nbsp;&nbsp;&nbsp;&nbsp;
            <span class="author-block">Haoyu Zhan</a></span>&nbsp;&nbsp;&nbsp;&nbsp;
            <span class="author-block"> <a href="https://yudongguo.github.io/">Yudong Guo</a>
            </span>&nbsp;&nbsp;&nbsp;&nbsp;
            <span class="author-block">
              <a href="http://staff.ustc.edu.cn/~juyong/">Juyong Zhang</a>
            </span>
          </div>

          <!-- <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>University of Science and Technology of China</span>&nbsp;&nbsp;&nbsp;&nbsp;
            <span class="author-block"><sup>2</sup>Image Derivative Inc</span>&nbsp;&nbsp;&nbsp;&nbsp;
          </div> -->
          <div class="is-size-5 publication-authors">
            <span class="author-block">University of Science and Technology of China</span>&nbsp;&nbsp;&nbsp;&nbsp;
            <!-- <span class="author-block"><sup>2</sup>Image Derivative Inc</span>&nbsp;&nbsp;&nbsp;&nbsp; -->
          </div>

          <!-- <div class="is-size-6 publication-authors">
            <span class="author-block">(This work was done when Xuan Gao, Chenglai Zhong and Jun Xiang were intern at Image Derivative Inc.)</span>
          </div> -->

          <div class="column has-text-centered">
            <div class="publication-links" style="margin-top: 0; margin-bottom: 2">
              <!-- PDF Link. -->
              <!--
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              -->
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <!-- Video Link. -->
              <!--
              <span class="link-block">
                <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>
              -->
              <!-- Code Link. -->
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code(Coming soon!)</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <!--
              <span class="link-block">
                <a href="https://github.com/google/nerfies/releases/tag/0.1"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a>
              </span>
              -->
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <!--
      <video id="teaser" autoplay muted loop playsinline height="100%">
        <source src="./resources/teaser.png"
                type="video/mp4">
      </video>
      -->
      <img src="https://github.com/Pbb-land/project_page_assets/blob/main/blob/main/PICA/teaser.jpg" class="center">
      <h2 class="subtitle has-text-centered" style="margin-top: 15px">
        Given multi-view RGB inputs (25 views in this example), PICA reconstructs the clothed avatar as a double-layer representation and applies novel pose animation and virtual try-on with a physics-integrated driving module.
      </h2>
    </div>
  </div>
</section>

<!--
<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Reconstructions</h2>

        <div class="embed-responsive embed-responsive-16by9">

          <iframe style="clip-path: inset(1px 1px)" src="https://sketchfab.com/playlists/embed?collection=abee3cc1a7a7436c804f2bd3aadc2acd" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture; fullscreen" mozallowfullscreen="true" webkitallowfullscreen="true" width="100%" height="100%" frameborder="0"></iframe>
        </div>
        

      </div>
    </div>

  </div>
</section>

-->

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3" style="margin-top: -30px">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            We introduce PICA, a novel representation for high-fidelity animatable clothed human avatars with physics-accurate dynamics, even for loose clothing. Previous neural rendering-based representations of animatable clothed humans typically employ a single model to represent both the clothing and the underlying body.While efficient, these approaches often fail to accurately represent complex garment dynamics, leading to incorrect deformations and noticeable rendering artifacts, especially for sliding or loose garments. Furthermore, previous works represent garment dynamics as pose-dependent deformations and facilitate novel pose animations in a data-driven manner. This often results in outcomes that do not faithfully represent the mechanics of motion and are prone to generating artifacts in out-of-distribution poses. To address these issues, we adopt two individual 3D Gaussian Splatting (3DGS) models  with different deformation characteristics, modeling the human body and clothing separately. This distinction allows for better handling of their respective motion characteristics. With this representation, we integrate a graph neural network (GNN)-based clothed body physics simulation module to ensure an accurate representation of clothing dynamics. Our method, through its carefully designed features, achieves high-fidelity rendering of clothed human bodies in complex and novel driving poses, significantly outperforming previous methods under the same settings.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
    <!-- Paper video. -->
    <!--
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <iframe src="https://www.youtube.com/embed/MrKrnHhk8IA?rel=0&amp;showinfo=0"
                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
        </div>
      </div>
    </div>
    -->
    <!--/ Paper video. -->
  </div>
</section>



<section class="section">
  <div class="container is-max-desktop">

    <!-- Method. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <h2 class="title is-3" style="margin-top: -20px">Pipeline</h2>

        <img src="https://github.com/Pbb-land/project_page_assets/blob/main/PICA/pipeline.jpg" class="center">
        <div class="content has-text-justified">
          <p style="margin-top: 30px">
            PICA represents clothed human avatars as two separate template meshes and corresponding mesh-aligned Gaussians. The avatar in canonical space is first deformed to observed space by non-rigid deformation and LBS, and then rasterized to the image space of the given camera with a pose-dependent color MLP. After reconstructing the avatar with appearance loss and geometry loss, PICA utilizes a hierarchical graph-based neural dynamics simulator to generate the simulation geometry sequence, which is rendered to the final animation result according to the trained appearance model.
          </p>
        </div>
        <div class="content has-text-centered">
          <video id="replay-video"
                 controls
                 preload
                 playsinline
                 loop
                 width="100%">
            <source src="https://raw.githubusercontent.com/xiangjun-xj/project_page_assets/master/FlashAvatar/pipeline.mp4"
                    type="video/mp4">
          </video>
        </div>

      </div>
    </div>
    <!--/ Animation. -->

  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">

    <!-- Results. -->
    <div class="columns is-centered ">
      <div class="column is-full-width">
        <h2 class="title is-3 has-text-centered" style="margin-top: -30px">Comparison</h2>

        <div class="content has-text-justified">
          <p>
            We compare our method with two representative works for novel view synthesis and novel pose animation. 
          </p>
        </div>
        <div class="content has-text-centered">
          <video id="replay-video"
                 controls
                 muted
                 preload
                 playsinline
                 loop
                 width="100%">
            <source src="https://raw.githubusercontent.com/xiangjun-xj/project_page_assets/master/FlashAvatar/comparison.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
    </div>

  </div>
</section>



<section class="section">
  <div class="container is-max-desktop">

    <!-- Comparisons. -->
    <div class="columns is-centered ">
      <div class="column is-full-width">
        <h2 class="title is-3 has-text-centered" style="margin-top: -30px">Training
        </h2>

        <div class="content has-text-justified">
          <p>
            We achieve a remarkable rendering speed over 300FPS. Meanwhile, we demonstrate that our training process is super efficient as well. We are able to recover the coarse appearance of head in several seconds and reconstruct the photo-realistic avatar with fine hair strands and textures within a couple of minutes. We conduct both training and inference on a single Nvidia RTX 3090.            
          </p>
        </div>
        
        <div class="content has-text-centered">
          <video id="replay-video"
                 controls
                 preload
                 playsinline
                 loop
                 width="100%">
            <source src="https://raw.githubusercontent.com/xiangjun-xj/project_page_assets/master/FlashAvatar/training.mp4"
                    type="video/mp4">
          </video>
        </div>


      </div>
    </div>

  </div>
</section>



<section class="section">
  <div class="container is-max-desktop">

    <!-- Ablation Studies. -->
    <div class="columns is-centered ">
      <div class="column is-full-width">
        <h2 class="title is-3 has-text-centered" style="margin-top: -30px">Novel View Synthesis</h2>

        <div class="content has-text-justified">
          <p>
            The basic representation of 3D head avatars in our method is pure non-neural 3D Gaussians, so we can freely adjust the global camera pose to generate target results with any desired rendering view.
          </p>
        </div>
        
        <div class="content has-text-centered">
          <video id="replay-video"
                 controls
                 muted
                 preload
                 playsinline
                 loop
                 width="100%">
            <source src="https://raw.githubusercontent.com/xiangjun-xj/project_page_assets/master/FlashAvatar/nvs.mp4"
                    type="video/mp4">
          </video>
        </div>

      </div>
    </div>

  </div>
</section>

<!-- <section class="hero is-light is-small">
  <div class="hero-body"> -->
<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-3 has-text-centered" style="margin-top: -30px">More Results</h2>
    <!-- Begin gallery-1. -->
    <div class="container">
      <div id="results-carousel1" class="carousel results-carousel">
        <div class="item g11">
          <video poster="" id="g11" controls muted loop playsinline height="100%">
            <source src="https://raw.githubusercontent.com/xiangjun-xj/project_page_assets/master/FlashAvatar/id3_12.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item g12">
          <video poster="" id="g12" controls muted loop playsinline height="100%">
            <source src="https://raw.githubusercontent.com/xiangjun-xj/project_page_assets/master/FlashAvatar/person0_12.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item g13">
          <video poster="" id="g13" controls muted loop playsinline height="100%">
            <source src="https://raw.githubusercontent.com/xiangjun-xj/project_page_assets/master/FlashAvatar/id5_12.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item g14">
          <video poster="" id="g14" controls muted loop playsinline height="100%">
            <source src="https://raw.githubusercontent.com/xiangjun-xj/project_page_assets/master/FlashAvatar/malte_12.mp4"
                    type="video/mp4">
          </video>
        </div>
        <!-- <div class="item g15">
          <video poster="" id="g15" controls muted loop playsinline height="100%">
            <source src="https://raw.githubusercontent.com/HaiyaoX/project_page_assets/main/video_demo/zcl_roman_x264.mp4"
                    type="video/mp4">
        </video>
        </div> -->
      </div>
    </div>
  <!-- <h2 class="subtitle has-text-centered" style="margin-top: 15px">
    We present CosAvatar, a text-driven portrait editing framework based on monocular dynamic NeRF. It allows for both global style editing (top row) and local attribute editing (bottom row) while ensuring strong consistency. It also enables expressive animation of the edited portrait.
  </h2> -->
  <div class="content has-text-justified">
    <p>
      In this paper, we have proposed FlashAvatar, which tightly combines a non-neural Gaussian-based radiance field with an explicit parametric face model and takes full advantage of their respective strengths. As a result, it can reconstruct a digital avatar from a monocular video in minutes and animate it at 300FPS while achieving photo-realistic rendering with full personalized details. Its efficiency, robustness, and representation ability have also been verified by extensive experimental results.
    </p>
  </div>

  </div>
</section>
<!-- End gallery. -->




<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <div class="content has-text-justified">
      <p>
        If you find our paper useful for your work please cite:
      </p>
    </div>
    <pre><code>
      @inproceedings{xiang2024flashavatar,
        author    = {Jun Xiang and Xuan Gao and Yudong Guo and Juyong Zhang},
        title     = {FlashAvatar: High-fidelity Head Avatar with Efficient Gaussian Embedding},
        booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
        year      = {2024},
      }
    </code></pre>
  </div>
</section>



<section class="section" id="Acknowledgements">
  <div class="container is-max-desktop content">
    <h2 class="title">Acknowledgements</h2>
    This work was supported by the National Natural Science Foundation of China (No. 62122071, No. 62272433) and the Youth Innovation Promotion Association CAS (No. 2018495).
  </div>
</section>



<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-ShareAlike 4.0 International License</a>.
            This webpage template is from <a href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>. 
            We sincerely thank <a href="https://keunhong.com/">Keunhong Park</a> for developing and open-sourcing this template.
          </p>
        </div>
      </div>
          <p></p>
        </div>
      </div>
</footer>

</body>
</html>
